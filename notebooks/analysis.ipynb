{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Image Authenticity Checker - Analysis Notebook\n",
    "\n",
    "This notebook provides comprehensive analysis and visualization for detecting AI-generated images.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Data Loading\n",
    "2. Feature Extraction and Analysis\n",
    "3. FFT Spectrum Visualization\n",
    "4. Model Training\n",
    "5. Evaluation and Metrics\n",
    "6. Feature Importance Analysis\n",
    "7. Error Analysis\n",
    "8. Interactive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path().absolute().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Project imports\n",
    "from config import DATA_DIR, REAL_IMAGES_DIR, FAKE_IMAGES_DIR, MODEL_DIR\n",
    "from features.fft_features import FFTFeatureExtractor\n",
    "from features.ela_features import ELAFeatureExtractor\n",
    "from features.texture_features import TextureFeatureExtractor\n",
    "from features.feature_fusion import FeatureFusion\n",
    "from model.classifier import AIImageClassifier\n",
    "from model.trainer import ModelTrainer\n",
    "\n",
    "# Plotting config\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Real Images: {REAL_IMAGES_DIR}\")\n",
    "print(f\"Fake Images: {FAKE_IMAGES_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset statistics\n",
    "from data.download_datasets import DatasetDownloader\n",
    "\n",
    "downloader = DatasetDownloader()\n",
    "stats = downloader.get_dataset_stats()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Real images: {stats['real_images']}\")\n",
    "print(f\"Fake images: {stats['fake_images']}\")\n",
    "print(f\"Total: {stats['total']}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "categories = ['Real', 'AI-Generated']\n",
    "counts = [stats['real_images'], stats['fake_images']]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(categories, counts, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Number of Images')\n",
    "ax.set_title('Dataset Class Distribution')\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "            str(count), ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample dataset if needed\n",
    "if stats['total'] < 10:\n",
    "    print(\"Downloading sample dataset...\")\n",
    "    downloader.download_sample_dataset(num_real=50, num_fake=50)\n",
    "    stats = downloader.get_dataset_stats()\n",
    "    print(f\"\\nDataset now contains {stats['total']} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature extractors\n",
    "fft_extractor = FFTFeatureExtractor()\n",
    "ela_extractor = ELAFeatureExtractor()\n",
    "texture_extractor = TextureFeatureExtractor()\n",
    "fusion = FeatureFusion(include_deep=False)\n",
    "\n",
    "# Collect sample images\n",
    "supported = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
    "real_images = [f for f in REAL_IMAGES_DIR.iterdir() if f.suffix.lower() in supported][:20]\n",
    "fake_images = [f for f in FAKE_IMAGES_DIR.iterdir() if f.suffix.lower() in supported][:20]\n",
    "\n",
    "print(f\"Sample real images: {len(real_images)}\")\n",
    "print(f\"Sample fake images: {len(fake_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for visualization\n",
    "real_fft_features = []\n",
    "fake_fft_features = []\n",
    "\n",
    "for img_path in tqdm(real_images, desc=\"Extracting real FFT features\"):\n",
    "    try:\n",
    "        features = fft_extractor.extract(img_path)\n",
    "        real_fft_features.append(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "for img_path in tqdm(fake_images, desc=\"Extracting fake FFT features\"):\n",
    "    try:\n",
    "        features = fft_extractor.extract(img_path)\n",
    "        fake_fft_features.append(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "print(f\"\\nExtracted features from {len(real_fft_features)} real and {len(fake_fft_features)} fake images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FFT Spectrum Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare radial power profiles\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Real images radial profiles\n",
    "for features in real_fft_features[:10]:\n",
    "    axes[0].plot(features.azimuthal_profile, alpha=0.5, color='green')\n",
    "axes[0].set_title('FFT Radial Power Profile - Real Images', fontsize=14)\n",
    "axes[0].set_xlabel('Frequency Bin')\n",
    "axes[0].set_ylabel('Normalized Power')\n",
    "\n",
    "# Fake images radial profiles  \n",
    "for features in fake_fft_features[:10]:\n",
    "    axes[1].plot(features.azimuthal_profile, alpha=0.5, color='red')\n",
    "axes[1].set_title('FFT Radial Power Profile - AI-Generated Images', fontsize=14)\n",
    "axes[1].set_xlabel('Frequency Bin')\n",
    "axes[1].set_ylabel('Normalized Power')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare key FFT features\n",
    "real_metrics = {\n",
    "    'spectral_ratio': [f.spectral_ratio for f in real_fft_features],\n",
    "    'spectral_entropy': [f.spectral_entropy for f in real_fft_features],\n",
    "    'spectral_flatness': [f.spectral_flatness for f in real_fft_features],\n",
    "    'gan_fingerprint': [f.gan_fingerprint_score for f in real_fft_features],\n",
    "}\n",
    "\n",
    "fake_metrics = {\n",
    "    'spectral_ratio': [f.spectral_ratio for f in fake_fft_features],\n",
    "    'spectral_entropy': [f.spectral_entropy for f in fake_fft_features],\n",
    "    'spectral_flatness': [f.spectral_flatness for f in fake_fft_features],\n",
    "    'gan_fingerprint': [f.gan_fingerprint_score for f in fake_fft_features],\n",
    "}\n",
    "\n",
    "# Create comparison boxplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, metric in zip(axes.flat, real_metrics.keys()):\n",
    "    data = [real_metrics[metric], fake_metrics[metric]]\n",
    "    bp = ax.boxplot(data, labels=['Real', 'AI-Generated'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('#2ecc71')\n",
    "    bp['boxes'][1].set_facecolor('#e74c3c')\n",
    "    ax.set_title(f'{metric.replace(\"_\", \" \").title()}', fontsize=12)\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "plt.suptitle('FFT Feature Comparison: Real vs AI-Generated', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = ModelTrainer(\n",
    "    real_dir=REAL_IMAGES_DIR,\n",
    "    fake_dir=FAKE_IMAGES_DIR,\n",
    "    include_deep=False\n",
    ")\n",
    "\n",
    "# Load dataset (limit for quick training)\n",
    "X, y = trainer.load_dataset(max_samples=100)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "trainer.split_data(X, y)\n",
    "\n",
    "print(f\"Training samples: {len(trainer.X_train)}\")\n",
    "print(f\"Validation samples: {len(trainer.X_val)}\")\n",
    "print(f\"Test samples: {len(trainer.X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest classifier\n",
    "results = trainer.train(algorithm='rf')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Algorithm: {results['algorithm']}\")\n",
    "print(f\"Test Accuracy: {results['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {results['test_auc']:.4f}\")\n",
    "print(f\"Model saved: {results['model_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model and evaluate\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "model = AIImageClassifier.load(results['model_path'])\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(trainer.X_test)\n",
    "y_prob = model.predict_proba(trainer.X_test)[:, 1]\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(trainer.y_test, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Real', 'AI-Generated'],\n",
    "            yticklabels=['Real', 'AI-Generated'])\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14)\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(trainer.y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve', fontsize=14)\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(trainer.y_test, y_pred, target_names=['Real', 'AI-Generated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds = precision_recall_curve(trainer.y_test, y_prob)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(recall, precision, color='blue', lw=2)\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision-Recall Curve', fontsize=14)\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "if model.feature_importance_ is not None:\n",
    "    feature_names = fusion.get_feature_names()[:len(model.feature_importance_)]\n",
    "    importance = model.feature_importance_\n",
    "    \n",
    "    # Top 20 features\n",
    "    top_k = 20\n",
    "    top_indices = np.argsort(importance)[-top_k:][::-1]\n",
    "    \n",
    "    top_features = [feature_names[i] if i < len(feature_names) else f'feature_{i}' for i in top_indices]\n",
    "    top_importance = importance[top_indices]\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    y_pos = np.arange(len(top_features))\n",
    "    \n",
    "    ax.barh(y_pos, top_importance, color='steelblue', edgecolor='black')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(top_features)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title('Top 20 Most Important Features', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Feature importance not available for this model type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.predict import ImagePredictor\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = ImagePredictor(model_path=results['model_path'])\n",
    "\n",
    "# Test on a sample image\n",
    "test_images = list(REAL_IMAGES_DIR.glob('*.jpg'))[:3] + list(FAKE_IMAGES_DIR.glob('*.png'))[:3]\n",
    "\n",
    "if test_images:\n",
    "    print(\"Sample Predictions:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for img_path in test_images:\n",
    "        try:\n",
    "            result = predictor.predict(img_path)\n",
    "            print(f\"\\nImage: {img_path.name}\")\n",
    "            print(f\"Prediction: {result.prediction}\")\n",
    "            print(f\"Confidence: {result.confidence:.2%} ({result.confidence_level})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting {img_path.name}: {e}\")\n",
    "else:\n",
    "    print(\"No test images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Visualize predictions\n",
    "if test_images:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    for ax, img_path in zip(axes.flat, test_images):\n",
    "        try:\n",
    "            # Load and display image\n",
    "            img = Image.open(img_path)\n",
    "            ax.imshow(img)\n",
    "            \n",
    "            # Get prediction\n",
    "            result = predictor.predict(img_path)\n",
    "            \n",
    "            # Color based on prediction\n",
    "            color = 'green' if result.prediction == 'Real' else 'red'\n",
    "            \n",
    "            ax.set_title(f\"{result.prediction}\\n{result.confidence:.1%} confidence\", \n",
    "                        color=color, fontsize=12, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            ax.set_title(f\"Error: {e}\")\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Predictions', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Dataset Loading** - Loaded real and AI-generated images\n",
    "2. **Feature Extraction** - Extracted FFT, ELA, texture, and noise features\n",
    "3. **FFT Analysis** - Compared frequency spectra between real and fake images\n",
    "4. **Model Training** - Trained Random Forest classifier\n",
    "5. **Evaluation** - Generated ROC curves, confusion matrix, and classification reports\n",
    "6. **Feature Importance** - Identified most discriminative features\n",
    "7. **Interactive Prediction** - Made predictions on new images\n",
    "\n",
    "### Key Findings\n",
    "- FFT spectral features show distinct patterns between real and AI-generated images\n",
    "- GAN fingerprint detection captures periodic upsampling artifacts\n",
    "- Ensemble methods typically achieve the best accuracy\n",
    "\n",
    "### Next Steps\n",
    "- Train on larger datasets (COCO, DiffusionDB)\n",
    "- Experiment with deep learning features\n",
    "- Deploy as API service"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
